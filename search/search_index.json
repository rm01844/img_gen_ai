{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83e\udde0 AI Image Generation API Documentation","text":"<p>Welcome to the AI Image Generation &amp; Editing API, powered by Google Vertex AI (Imagen Models) and deployed securely on Railway.</p> <p>This service allows developers to: - \ud83c\udfa8 Generate images from text prompts - \ud83e\ude84 Edit existing images using AI guidance - \ud83d\udd10 Access both web UI and REST API endpoints with token-based authentication</p>"},{"location":"#documentation-overview","title":"\ud83d\udcd8 Documentation Overview","text":"Section Description \ud83e\udde9 API Reference Details of each endpoint (<code>/generate</code>, <code>/edit</code>), request/response formats, and sample payloads \ud83e\uddf0 Application Overview Explains how the Flask app, Vertex AI integration, and authentication system work \ud83d\ude80 Deployment Guide Step-by-step guide for deploying to Railway or another cloud platform \ud83d\udcc4 OpenAPI Spec Swagger schema to auto-import into Postman / Insomnia / client SDKs"},{"location":"#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"#base-url","title":"Base URL","text":"<p>https://web-production-fc79.up.railway.app/</p> <p>All endpoints are relative to this base URL.</p>"},{"location":"#endpoints","title":"\ud83d\udd27 Endpoints","text":"Endpoint Method Description <code>/generate</code> POST Generate image(s) from text prompt <code>/edit</code> POST Edit uploaded image based on prompt <code>/login</code> GET/POST Superadmin login (OTP required) <code>/logout</code> GET End session"},{"location":"#available-models","title":"\ud83e\udde0 Available Models","text":"Function Model ID Version Provider Text \u2192 Image <code>imagen-4.0-generate-001</code> v4.0 Google Vertex AI Image \u2192 Image (Edit) <code>imagen-3.0-capability-001</code> v3.0 Google Vertex AI Text \u2192 Text (Prompt) <code>gemini 2.5-pro</code> v2.5 Google Vertex AI <p>\ud83e\udded Navigation For API details \u2192 start with API Reference</p> <p>For deployment or local setup \u2192 see Deployment Guide</p> <p>For technical app overview \u2192 see Application Structure</p> <p>For client-side import \u2192 use OpenAPI Spec</p>"},{"location":"deployment/","title":"Deployment Guide","text":""},{"location":"deployment/#docsdeploymentmd","title":"\ud83e\udde9 <code>docs/deployment.md</code>","text":""},{"location":"deployment/#deployment-guide","title":"\ud83d\ude80 Deployment Guide","text":"<p>This document explains how to deploy and configure the AI Image Generator API using Google Vertex AI and Flask.</p>"},{"location":"deployment/#environment-variables","title":"\ud83e\uddf0 Environment Variables","text":"<p>Create a <code>.env</code> file (or configure on Railway):</p> Variable Description Example <code>PROJECT_ID</code> Your Google Cloud project ID <code>your_project_ID</code> <code>LOCATION</code> Vertex AI region <code>us-central1</code> <code>SERVICE_KEY_JSON</code> JSON contents of the service account key <code>service account key (.json)</code> <code>API_TOKEN</code> Secret used for client API authentication <code>API_TOKEN</code> <code>SUPERADMIN_OTP</code> OTP for admin web login <code>custom_otp</code> <code>SECRET_KEY</code> Flask session encryption key <code>random_flask_secret</code> <code>PORT</code> App port <code>8080</code> <p>\u26a0\ufe0f Never commit <code>.env</code> or <code>.json</code> files to GitHub.</p>"},{"location":"deployment/#directory-structure","title":"\ud83e\uddf1 Directory Structure","text":"<pre><code>Img_gen_AI/\n\u251c\u2500\u2500 img_gen_ai/\n\u2502   \u251c\u2500\u2500 app.py\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 static/\n\u2502   \u251c\u2500\u2500 templates/\n\u2502       \u251c\u2500\u2500 index.html\n\u2502       \u2514\u2500\u2500 login.html\n\u2514\u2500\u2500 docs/\n\u2502   \u251c\u2500\u2500 index.md \n\u2502   \u251c\u2500\u2500 reference/\n\u2502       \u2514\u2500\u2500 api.md\n\u2502       \u2514\u2500\u2500 app.md\n\u2502   \u2514\u2500\u2500 deployment.md\n\u251c\u2500\u2500 Procfile\n\u251c\u2500\u2500 mkdocs.yml\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"deployment/#deployment-railway","title":"\u2699\ufe0f Deployment (Railway)","text":"<ol> <li>Push to GitHub</li> <li> <p>Ensure your <code>requirements.txt</code> and <code>Procfile</code> exist.</p> </li> <li> <p>Create Railway project</p> </li> <li>Connect GitHub repo.</li> <li> <p>Set environment variables in Settings \u2192 Variables.</p> </li> <li> <p>Build &amp; deploy    Railway auto-detects Flask from <code>Procfile</code>:</p> </li> </ol> <p>web: gunicorn img_gen_ai.app:app</p> <ol> <li>Access the app</li> </ol> <p>https://example.railway.app/login</p>"},{"location":"deployment/#security-checklist","title":"\ud83d\udd10 Security Checklist","text":"<ul> <li>[ ] Store tokens and service keys only in environment variables  </li> <li>[ ] Use long, random API tokens (\u2265 32 chars)  </li> <li>[ ] Rotate API tokens periodically  </li> <li>[ ] Restrict GCP service account to minimal permissions  </li> <li>[ ] Enable HTTPS (Railway provides automatically)</li> </ul>"},{"location":"deployment/#under-the-hood","title":"\ud83e\udde0 Under the Hood","text":"Component Purpose Flask Web framework and routing Vertex AI Imagen AI image generation and editing Google Service Account Authenticates your app with Vertex Gunicorn Production web server MkDocs Documentation generator"},{"location":"deployment/#verification","title":"\u2705 Verification","text":"<p>After deployment, test your API using: <pre><code>curl -X POST https://example.railway.app/api \\\n-H \"Authorization: Bearer &lt;YOUR_API_TOKEN&gt;\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\"prompt\":\"a mountain landscape in watercolor\",\"number_of_images\":1}'\n</code></pre> Expected Response:</p> <p>{   \"image_urls\": [\"/static/generated_.png\"] }"},{"location":"deployment/#credits","title":"\ud83e\uddfe Credits","text":"<p>Google Cloud Vertex AI Imagen</p> <p>Flask for backend</p> <p>Railway.app for deployment</p> <p>MkDocs for documentation</p>"},{"location":"reference/api/","title":"\ud83e\udde0 AI Image Generation API","text":"<p>This API enables developers to generate and edit images using Google Vertex AI\u2019s Imagen models through a secure Flask REST interface.</p>"},{"location":"reference/api/#base-url","title":"\ud83d\udd17 Base URL","text":"<p>The application is deployed and hosted on Railway.app. This URL serves as the root endpoint for all API requests.</p> <p>Base URL: https://web-production-fc79.up.railway.app/</p> <p>Example: To access <code>/generate</code>, send a POST request to <code>https://web-production-fc79.up.railway.app/generate</code></p>"},{"location":"reference/api/#authentication","title":"\ud83d\udd10 Authentication","text":"<p>All API endpoints require a valid Bearer token to be included in the request header. This token is used to authenticate and authorize client requests.</p> <p>Header Format:</p> <p>Authorization: Bearer"},{"location":"reference/api/#obtaining-the-token","title":"\ud83d\udd11 Obtaining the Token","text":"<p>Bearer tokens are provided by the API administrator upon onboarding. Each client or integration partner will receive a unique token associated with their account.</p> <p>If you have not received your token, please contact the API administrator or project owner.</p> <p>\u26a0\ufe0f Important: - Do not share your token publicly or embed it in client-side code. - Tokens are tied to your project identity and usage limits. - Rotate tokens periodically or immediately if compromised.</p>"},{"location":"reference/api/#example-authenticated-request","title":"\ud83e\udde9 Example: Authenticated Request","text":"<pre><code>curl -X POST https://web-production-fc79.up.railway.app/generate \\\n  -H \"Authorization: Bearer your_api_token_here\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"prompt\":\"a serene landscape with mountains and clouds\"}'\n</code></pre>"},{"location":"reference/api/#requirements","title":"\ud83d\udce6 Requirements","text":"<ul> <li>Python 3.10+</li> <li>Google Cloud Vertex AI API enabled and copy the API_TOKEN</li> <li>A service account key (.json) with the <code>Vertex AI User</code> and <code>Storage Admin</code> roles</li> <li>Railway.app or Render account for deployment</li> <li>MkDocs (optional) for documentation hosting</li> </ul>"},{"location":"reference/api/#endpoints","title":"\u2728 Endpoints","text":""},{"location":"reference/api/#post-generate","title":"POST /generate","text":"<p>Generate one or more images from a text prompt.</p> <p>Request Body</p> Field Type Required Description <code>prompt</code> string \u2705 Description of the image to generate <code>number_of_images</code> int \u274c Default: <code>1</code>, number of images to create <code>aspect_ratio</code> string \u274c Default: <code>\"1:1\"</code>, aspect ratio such as <code>16:9</code>, <code>3:4</code>, <code>9:16</code> <code>negative_prompt</code> string \u274c Optional text describing what to avoid <p>Example</p> <p>{   prompt: \"A futuristic city skyline at sunset\",   number_of_images: 2,   aspect_ratio: \"16:9\" }</p> <p>Response</p> <p>{   image_urls: [     \"/static/generated_8fa3b3.png\",     \"/static/generated_19df1d.png\"   ] }</p> <p>Underlying Model: imagen-4.0-generate-001 Provider: Google Vertex AI</p>"},{"location":"reference/api/#post-edit","title":"POST /edit","text":"<p>This endpoint enables AI-powered image editing by combining Google Gemini 2.5 Pro (for intelligent prompt refinement and feedback) with Vertex AI Imagen 3.0 (for photo-realistic image generation).</p>"},{"location":"reference/api/#workflow-overview","title":"\ud83e\udde9 Workflow Overview","text":"<ol> <li>Prompt Refinement (Gemini 2.5 Pro)</li> <li>The user\u2019s raw text prompt is rewritten by Gemini to be concise, spatially descriptive, and better aligned with Imagen\u2019s generation semantics.</li> <li> <p>Example transformation:      &gt; \"Turn this person into an action figure in orange packaging\"      \u2192 \"Create a high-resolution product photo of the same person as a realistic action figure packaged in an orange blister pack with accessories arranged symmetrically and a name label at the top.\"</p> </li> <li> <p>Image Generation (Vertex AI Imagen 3.0)</p> </li> <li> <p>The refined prompt and uploaded reference image are sent to Imagen to produce the edited output.</p> </li> <li> <p>Automated Feedback (Gemini Vision Review)</p> </li> <li>Gemini optionally evaluates the generated image for identity and layout consistency,      then suggests a refined prompt for re-generation to improve results.</li> </ol>"},{"location":"reference/api/#authentication_1","title":"\ud83d\udd10 Authentication","text":"<p>All requests must include a valid Bearer Token in the HTTP header:</p> <pre><code>Authorization: Bearer &lt;YOUR_API_TOKEN&gt; \n</code></pre> <p>Request (multipart/form-data)</p> Field Type Required Description <code>image</code> file \u2705 The source image to edit <code>prompt</code> string \u2705 Natural-language description of desired changes <code>number_of_images</code> int \u274c Default: <code>1</code>, number of variations to return <code>negative_prompt</code> string \u274c Optional text describing elements to avoid. <code>edit_strength</code> float \u274c Degree of transformation, range 0.1\u20131.0 (default 0.55) <code>enhance_detail</code> bool \u274c Enhance visual detail and sharpness (true by default) <p>Example </p> <pre><code>curl -X POST https://web-production-fc79.up.railway.app/edit \\\n  -H \"Authorization: Bearer &lt;YOUR_API_TOKEN&gt;\" \\\n  -F \"image=@ben_philip.jpg\" \\\n  -F \"prompt=Create a photo-realistic action figure of the same person in orange packaging with accessories neatly arranged.\" \\\n  -F \"number_of_images=2\"\n</code></pre> <p>Response</p> <p>{   image_urls: [     \"/static/edited_a13c0d.png\",     \"/static/edited_b28d9f.png\"   ] }</p> <p>Underlying Model: imagen-3.0-capability-001 + Gemini 1.5 Pro Provider: Google Vertex AI</p>"},{"location":"reference/api/#architecture-overview","title":"Architecture Overview","text":"<pre><code>graph TD\n  A[Client Request (POST /edit)] --&gt; B[Flask API (Python)]\n  B --&gt;|Multipart form: prompt + image| C[Gemini 2.5 Pro (Prompt Refinement)]\n  C --&gt;|Refined prompt| D[Vertex AI Imagen 3.0 (Image Editing)]\n  D --&gt;|Generated image URLs| E[Gemini Vision Review (Optional Feedback)]\n  E --&gt;|Revised prompt (if needed)| D\n  D --&gt;|Final image URLs| F[Flask API Response]\n  F --&gt;|JSON Response| G[Client (Web UI / API Consumer)]\n</code></pre>"},{"location":"reference/api/#error-handling","title":"\u26a0\ufe0f Error Handling","text":"HTTP Code Meaning Example Cause 400 Bad Request Missing prompt or file 401 Unauthorized Invalid or missing token 404 Not Found Endpoint mismatch 500 Internal Error Vertex API or server issue <p>\ud83e\udde0 Notes</p> <ul> <li> <p>Images are saved temporarily under /static/.</p> </li> <li> <p>Watermarks may be applied by Vertex AI for compliance.</p> </li> <li> <p>The API auto-refreshes credentials from your GCP service account.</p> </li> </ul>"},{"location":"reference/app/","title":"\ud83e\udde9 AI Image Generator &amp; Editing \u2014 API Reference","text":"<p>This section documents all Flask routes and functions exposed by the backend.</p>"},{"location":"reference/app/#img_gen_ai.app--ai-image-generator-api","title":"AI Image Generator API","text":"<p>A Flask application that provides endpoints to generate and edit images using Google Vertex AI's Imagen models.</p> <p>This module includes authentication, text-to-image generation, and image-editing endpoints.</p>"},{"location":"reference/app/#img_gen_ai.app.login_required","title":"login_required","text":"<pre><code>login_required(f)\n</code></pre> <p>Decorator that restricts access to logged-in admin users.</p> Source code in <code>img_gen_ai/app.py</code> <pre><code>def login_required(f):\n    \"\"\"Decorator that restricts access to logged-in admin users.\"\"\"\n    from functools import wraps\n\n    @wraps(f)\n    def decorated_function(*args, **kwargs):\n        if not session.get(\"logged_in\"):\n            flash(\"Please log in to access the generator.\", \"warning\")\n            return redirect(url_for(\"login\"))\n        return f(*args, **kwargs)\n    return decorated_function\n</code></pre>"},{"location":"reference/app/#img_gen_ai.app.login","title":"login","text":"<pre><code>login()\n</code></pre> <p>Superadmin login page with OTP validation.</p> <p>Returns:</p> Name Type Description <code>Response</code> <code>Response</code> <p>Renders the login form or redirects to the index if OTP is valid.</p> Source code in <code>img_gen_ai/app.py</code> <pre><code>@app.route(\"/login\", methods=[\"GET\", \"POST\"])\ndef login() -&gt; Response:\n    \"\"\"Superadmin login page with OTP validation.\n\n    Returns:\n        Response: Renders the login form or redirects to the index if OTP is valid.\n    \"\"\"\n    stored_otp = (os.getenv(\"SUPERADMIN_OTP\") or \"\").strip().replace(\n        \"\\n\", \"\").replace(\"\\r\", \"\").replace(\" \", \"\")\n\n    if request.method == \"POST\":\n        entered_otp = (request.form.get(\"otp\") or \"\").strip().replace(\n            \"\\n\", \"\").replace(\"\\r\", \"\").replace(\" \", \"\")\n        print(\n            f\"\ud83d\udd0d DEBUG OTP | Entered='{entered_otp}' | Stored='{stored_otp}' | Match={entered_otp == stored_otp}\")\n\n        if entered_otp == stored_otp:\n            session.permanent = True\n            session[\"is_admin\"] = True\n            print(\"\u2705 OTP accepted \u2014 redirecting to index.\")\n            return redirect(url_for(\"index\"))\n        else:\n            print(\"\u274c Invalid OTP entered.\")\n            return render_template_string(\"\"\"\n                &lt;!DOCTYPE html&gt;\n                &lt;html lang=\"en\"&gt;\n                &lt;head&gt;\n                    &lt;meta charset=\"UTF-8\"&gt;\n                    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n                    &lt;title&gt;Invalid OTP&lt;/title&gt;\n                    &lt;style&gt;\n                        body { font-family: Arial; text-align: center; margin-top: 100px; }\n                        a { color: #007bff; text-decoration: none; }\n                    &lt;/style&gt;\n                &lt;/head&gt;\n                &lt;body&gt;\n                    &lt;h2 style='color:red;'&gt;Invalid OTP&lt;/h2&gt;\n                    &lt;a href='/login'&gt;Try again&lt;/a&gt;\n                &lt;/body&gt;\n                &lt;/html&gt;\n            \"\"\")\n\n    return render_template_string(\"\"\"\n        &lt;!DOCTYPE html&gt;\n        &lt;html lang=\"en\"&gt;\n        &lt;head&gt;\n            &lt;meta charset=\"UTF-8\"&gt;\n            &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n            &lt;title&gt;Superadmin Login&lt;/title&gt;\n            &lt;style&gt;\n                body {\n                    font-family: Arial, sans-serif;\n                    display: flex;\n                    flex-direction: column;\n                    align-items: center;\n                    justify-content: center;\n                    height: 100vh;\n                    background-color: #121212;\n                    color: white;\n                }\n                input, button {\n                    padding: 10px;\n                    margin: 10px;\n                    border: none;\n                    border-radius: 6px;\n                }\n                input {\n                    width: 200px;\n                    text-align: center;\n                }\n                button {\n                    background-color: #4CAF50;\n                    color: white;\n                    cursor: pointer;\n                }\n                button:hover {\n                    background-color: #45a049;\n                }\n            &lt;/style&gt;\n        &lt;/head&gt;\n        &lt;body&gt;\n            &lt;form method=\"POST\"&gt;\n                &lt;h2&gt;Enter Superadmin OTP&lt;/h2&gt;\n                &lt;input type=\"password\" name=\"otp\" placeholder=\"Enter OTP\" required&gt;\n                &lt;button type=\"submit\"&gt;Login&lt;/button&gt;\n            &lt;/form&gt;\n        &lt;/body&gt;\n        &lt;/html&gt;\n    \"\"\")\n</code></pre>"},{"location":"reference/app/#img_gen_ai.app.restrict_access","title":"restrict_access","text":"<pre><code>restrict_access()\n</code></pre> <p>Restrict access to authorized users only.</p> Source code in <code>img_gen_ai/app.py</code> <pre><code>@app.before_request\ndef restrict_access() -&gt; Response | None:\n    \"\"\"Restrict access to authorized users only.\"\"\"\n    if request.endpoint not in (\"login\", \"static\") and not session.get(\"is_admin\"):\n        return redirect(url_for(\"login\"))\n</code></pre>"},{"location":"reference/app/#img_gen_ai.app.index","title":"index","text":"<pre><code>index()\n</code></pre> <p>Render the main web interface.</p> Source code in <code>img_gen_ai/app.py</code> <pre><code>@app.route(\"/\")\ndef index() -&gt; Response:\n    \"\"\"Render the main web interface.\"\"\"\n    return render_template(\"index.html\")\n</code></pre>"},{"location":"reference/app/#img_gen_ai.app.generate_image","title":"generate_image","text":"<pre><code>generate_image()\n</code></pre> <p>Generate image(s) using Vertex AI Imagen model.</p> <p>This endpoint generates one or more images based on the user's prompt and options.</p> <p>Request Body (JSON):     prompt (str): The image description to generate.     number_of_images (int, optional): Number of images to generate (default=1).     aspect_ratio (str, optional): Aspect ratio, e.g. \"1:1\" or \"16:9\".     negative_prompt (str, optional): Objects/concepts to avoid.</p> <p>Returns:</p> Name Type Description <code>Response</code> <code>Response</code> <p>JSON containing a list of image URLs or an error message.</p> Source code in <code>img_gen_ai/app.py</code> <pre><code>@app.route(\"/generate\", methods=[\"POST\"])\ndef generate_image() -&gt; Response:\n    \"\"\"Generate image(s) using Vertex AI Imagen model.\n\n    This endpoint generates one or more images based on the user's prompt and options.\n\n    Request Body (JSON):\n        prompt (str): The image description to generate.\n        number_of_images (int, optional): Number of images to generate (default=1).\n        aspect_ratio (str, optional): Aspect ratio, e.g. \"1:1\" or \"16:9\".\n        negative_prompt (str, optional): Objects/concepts to avoid.\n\n    Returns:\n        Response: JSON containing a list of image URLs or an error message.\n    \"\"\"\n    try:\n        data = request.get_json()\n        prompt = data.get(\"prompt\")\n        number_of_images = data.get(\"number_of_images\", \"1\")\n        aspect_ratio = data.get(\"aspect_ratio\", \"1:1\")\n        negative_prompt = data.get(\"negative_prompt\", \"\")\n\n        if not prompt:\n            return jsonify({\"error\": \"No prompt provided\"}), 400\n\n        # Load Imagen model\n        model = ImageGenerationModel.from_pretrained(\"imagen-4.0-generate-001\")\n\n        # Generate image\n        result = model.generate_images(\n            prompt=prompt,\n            number_of_images=int(number_of_images),\n            aspect_ratio=aspect_ratio,\n            negative_prompt=negative_prompt,\n            person_generation=\"allow_all\",\n            safety_filter_level=\"block_few\",\n            add_watermark=True,\n        )\n\n        # Save image to static folder\n        image_urls = []\n        for img in result.images:\n            static_dir = os.path.join(os.path.dirname(__file__), \"static\")\n            os.makedirs(static_dir, exist_ok=True)\n\n            filename = f\"generated_{uuid.uuid4().hex}.png\"\n            output_path = os.path.join(static_dir, filename)\n            img.save(output_path)\n\n            filename = os.path.basename(output_path)\n            image_urls.append(f\"/static/{filename}?v={int(time.time())}\")\n\n        # Return image URL with timestamp (cache-buster)\n        return jsonify({\"image_urls\": image_urls})\n\n    except Exception as e:\n        print(\"Error:\", str(e))\n        return jsonify({\"error\": str(e)}), 500\n</code></pre>"},{"location":"reference/app/#img_gen_ai.app.refine_prompt","title":"refine_prompt","text":"<pre><code>refine_prompt(raw_prompt, reference_description='')\n</code></pre> <p>Use Gemini 2.5 Pro to rewrite user prompt for Imagen clarity.</p> Source code in <code>img_gen_ai/app.py</code> <pre><code>def refine_prompt(raw_prompt: str, reference_description: str = \"\") -&gt; str:\n    \"\"\"Use Gemini 2.5 Pro to rewrite user prompt for Imagen clarity.\"\"\"\n    try:\n        response = gemini.generate_content(\n            f\"Rewrite this prompt for Vertex Imagen 3. \"\n            f\"Make it concise, photo-realistic, and layout-explicit.\\n\\n\"\n            f\"Prompt: {raw_prompt}\\n\\nReference: {reference_description}\"\n        )\n        return response.text\n    except Exception as e:\n        print(\"\u26a0\ufe0f Gemini refinement failed:\", e)\n        return raw_prompt\n</code></pre>"},{"location":"reference/app/#img_gen_ai.app.generate_with_imagen","title":"generate_with_imagen","text":"<pre><code>generate_with_imagen(prompt, img_b64, num_images=1)\n</code></pre> <p>Send a request to Vertex Imagen and return generated image URLs.</p> Source code in <code>img_gen_ai/app.py</code> <pre><code>def generate_with_imagen(prompt: str, img_b64: str, num_images: int = 1) -&gt; list[str]:\n    \"\"\"Send a request to Vertex Imagen and return generated image URLs.\"\"\"\n    body = {\n        \"instances\": [\n            {\n                \"prompt\": prompt,\n                \"referenceImages\": [\n                    {\n                        \"referenceType\": \"REFERENCE_TYPE_RAW\",\n                        \"referenceId\": 1,\n                        \"referenceImage\": {\n                            \"bytesBase64Encoded\": img_b64\n                        },\n                    }\n                ],\n            }\n        ],\n        \"parameters\": {\"sampleCount\": num_images},\n    }\n\n    headers = {\n        \"Authorization\": f\"Bearer {credentials.token}\",\n        \"Content-Type\": \"application/json\",\n    }\n\n    response = requests.post(ENDPOINT, headers=headers, json=body)\n    response.raise_for_status()\n    result = response.json()\n\n    image_urls = []\n    static_dir = os.path.join(os.path.dirname(__file__), \"static\")\n    os.makedirs(static_dir, exist_ok=True)\n\n    for pred in result.get(\"predictions\", []):\n        data_b64 = pred.get(\"bytesBase64Encoded\")\n        if not data_b64:\n            continue\n        filename = f\"edited_{uuid.uuid4().hex}.png\"\n        output_path = os.path.join(static_dir, filename)\n        with open(output_path, \"wb\") as f:\n            f.write(base64.b64decode(data_b64))\n        image_urls.append(f\"/static/{filename}?v={int(time.time())}\")\n\n    return image_urls\n</code></pre>"},{"location":"reference/app/#img_gen_ai.app.detect_face_bbox","title":"detect_face_bbox","text":"<pre><code>detect_face_bbox(image_path)\n</code></pre> <p>Return (x, y, w, h) face bbox using OpenCV Haar as a lightweight fallback.</p> Source code in <code>img_gen_ai/app.py</code> <pre><code>def detect_face_bbox(image_path: str) -&gt; Tuple[int, int, int, int] | None:\n    \"\"\"Return (x, y, w, h) face bbox using OpenCV Haar as a lightweight fallback.\"\"\"\n    img = cv2.imread(image_path)\n    if img is None:\n        return None\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    # Built-in cascade (simple but robust enough for crop)\n    face_cascade = cv2.CascadeClassifier(\n        cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n    faces = face_cascade.detectMultiScale(gray, 1.2, 5, minSize=(80, 80))\n    if len(faces) == 0:\n        return None\n    # choose largest face\n    faces = sorted(faces, key=lambda b: b[2]*b[3], reverse=True)\n    return tuple(int(v) for v in faces[0])\n</code></pre>"},{"location":"reference/app/#img_gen_ai.app.crop_face","title":"crop_face","text":"<pre><code>crop_face(image_path)\n</code></pre> <p>Save a padded face crop next to the temp image and return its path.</p> Source code in <code>img_gen_ai/app.py</code> <pre><code>def crop_face(image_path: str) -&gt; str | None:\n    \"\"\"Save a padded face crop next to the temp image and return its path.\"\"\"\n    img = cv2.imread(image_path)\n    if img is None:\n        return None\n    bbox = detect_face_bbox(image_path)\n    if not bbox:\n        return None\n    x, y, w, h = bbox\n    # pad box\n    pad = int(0.35 * max(w, h))\n    x0 = max(0, x - pad)\n    y0 = max(0, y - pad)\n    x1 = min(img.shape[1], x + w + pad)\n    y1 = min(img.shape[0], y + h + pad)\n    face = img[y0:y1, x0:x1]\n    face_path = os.path.join(tempfile.gettempdir(),\n                             f\"face_{uuid.uuid4().hex}.png\")\n    cv2.imwrite(face_path, face)\n    return face_path\n</code></pre>"},{"location":"reference/app/#img_gen_ai.app.build_structured_prompt","title":"build_structured_prompt","text":"<pre><code>build_structured_prompt(user_prompt)\n</code></pre> <p>Normalize and structure the prompt into sections to improve instruction following.</p> Source code in <code>img_gen_ai/app.py</code> <pre><code>def build_structured_prompt(user_prompt: str) -&gt; str:\n    \"\"\"Normalize and structure the prompt into sections to improve instruction following.\"\"\"\n    # You already refine with Gemini; this complements it with layout scaffolding.\n    lines = [ln.strip() for ln in user_prompt.split(\"\\n\") if ln.strip()]\n    prompt = (\n        \"TASK: Edit the reference image while preserving the person's identity and clothing.\\n\"\n        \"LAYOUT: Respect a single, centered packaging with arranged accessories.\\n\"\n        \"CONTENT:\\n\"\n        + \"\\n\".join([f\"- {ln}\" for ln in lines]) +\n        \"\\nSTYLE: studio lighting, product photo, realistic materials, sharp focus.\\n\"\n        \"TEXT: Ben Philip as top label (clear, sharp, correctly spelled).\\n\"\n    )\n    return prompt\n</code></pre>"},{"location":"reference/app/#img_gen_ai.app.restore_face_if_available","title":"restore_face_if_available","text":"<pre><code>restore_face_if_available(image_path)\n</code></pre> <p>Lightweight ONNX-based face enhancement using InsightFace (no Torch).</p> Source code in <code>img_gen_ai/app.py</code> <pre><code>def restore_face_if_available(image_path: str) -&gt; str:\n    \"\"\"Lightweight ONNX-based face enhancement using InsightFace (no Torch).\"\"\"\n    global _face_app\n    try:\n        if _face_app is None:\n            # Initialize only once\n            _face_app = FaceAnalysis(name=\"buffalo_l\", providers=[\n                                     \"CPUExecutionProvider\"])\n            _face_app.prepare(ctx_id=0)\n\n        img = cv2.imread(image_path)\n        if img is None:\n            raise ValueError(\"Cannot read input image\")\n\n        faces = _face_app.get(img)\n        if not faces:\n            print(\"\u26a0\ufe0f No face detected \u2014 skipping enhancement.\")\n            return image_path\n\n        # Simple enhancement: blend detected face region for smoother texture\n        for f in faces:\n            box = f.bbox.astype(int)\n            x1, y1, x2, y2 = box\n            roi = img[y1:y2, x1:x2]\n            if roi.size == 0:\n                continue\n            # Apply mild bilateral filtering + contrast boost\n            smooth = cv2.bilateralFilter(roi, 9, 75, 75)\n            enhanced = cv2.addWeighted(smooth, 0.6, roi, 0.4, 8)\n            img[y1:y2, x1:x2] = enhanced\n\n        output_path = image_path.replace(\".png\", \"_restored.png\")\n        cv2.imwrite(output_path, img)\n        return output_path\n\n    except Exception as e:\n        print(f\"\u26a0\ufe0f Skipping restoration: {e}\")\n        return image_path\n</code></pre>"},{"location":"reference/app/#img_gen_ai.app.edit_image","title":"edit_image","text":"<pre><code>edit_image()\n</code></pre> <p>Edit an uploaded image using Gemini + Imagen hybrid workflow.</p> This endpoint accepts <ul> <li>An uploaded image file</li> <li>A prompt describing desired changes</li> <li>Optional number_of_images parameter</li> </ul> It performs <p>1\ufe0f\u20e3 Prompt refinement via Gemini 2.5 Pro 2\ufe0f\u20e3 Image editing via Vertex AI Imagen 3 3\ufe0f\u20e3 Gemini Vision feedback + re-generation</p> Source code in <code>img_gen_ai/app.py</code> <pre><code>@app.route(\"/edit\", methods=[\"POST\"])\ndef edit_image() -&gt; Response:\n    \"\"\"Edit an uploaded image using Gemini + Imagen hybrid workflow.\n\n    This endpoint accepts:\n      - An uploaded image file\n      - A prompt describing desired changes\n      - Optional number_of_images parameter\n\n    It performs:\n      1\ufe0f\u20e3 Prompt refinement via Gemini 2.5 Pro\n      2\ufe0f\u20e3 Image editing via Vertex AI Imagen 3\n      3\ufe0f\u20e3 Gemini Vision feedback + re-generation\n    \"\"\"\n    try:\n        raw_prompt = request.form.get(\n            \"prompt\", \"\").strip() or \"Modify this image\"\n        num_images = int(request.form.get(\"number_of_images\", 1))\n\n        if \"image\" not in request.files:\n            return jsonify({\"error\": \"No image uploaded\"}), 400\n\n        uploaded = request.files[\"image\"]\n        temp_path = os.path.join(\n            tempfile.gettempdir(), f\"upload_{uuid.uuid4().hex}.png\")\n        uploaded.save(temp_path)\n\n        # \ud83e\udde0 1\ufe0f\u20e3 Gemini refinement\n        prompt = refine_prompt(raw_prompt)\n\n        # \ud83e\udde0 2\ufe0f\u20e3 Base64 encode the image\n        with open(temp_path, \"rb\") as f:\n            full_b64 = base64.b64encode(f.read()).decode(\"utf-8\")\n\n        # \ud83e\udde0 3\ufe0f\u20e3 Construct Imagen-3-compatible request\n        body = {\n            \"instances\": [\n                {\n                    \"prompt\": prompt,\n                    \"image_bytes_base64\": full_b64\n                }\n            ],\n            \"parameters\": {\n                \"sampleCount\": num_images\n            }\n        }\n\n        credentials.refresh(Request())\n        headers = {\n            \"Authorization\": f\"Bearer {credentials.token}\",\n            \"Content-Type\": \"application/json\",\n        }\n\n        print(\"\ud83d\udd0d Sending payload keys:\", list(body[\"instances\"][0].keys()))\n\n        resp = requests.post(ENDPOINT, headers=headers, json=body, timeout=120)\n        print(\"\ud83d\udd0d Status:\", resp.status_code)\n        if resp.status_code != 200:\n            print(\"\ud83d\udd0d Raw Response:\", resp.text)\n            return jsonify({\"error\": f\"Vertex returned {resp.status_code}: {resp.text}\"}), 400\n\n        result = resp.json()\n        preds = result.get(\"predictions\", [])\n\n        if not preds:\n            return jsonify({\"error\": \"No predictions returned.\"}), 400\n\n        static_dir = os.path.join(os.path.dirname(__file__), \"static\")\n        os.makedirs(static_dir, exist_ok=True)\n        urls = []\n\n        for pred in preds:\n            b64 = pred.get(\"bytesBase64Encoded\")\n            if not b64:\n                continue\n            fn = f\"edited_{uuid.uuid4().hex}.png\"\n            output_path = os.path.join(static_dir, fn)\n            with open(output_path, \"wb\") as f:\n                f.write(base64.b64decode(b64))\n            output_path = restore_face_if_available(output_path)\n            urls.append(\n                f\"/static/{os.path.basename(output_path)}?v={int(time.time())}\")\n\n        return jsonify({\"image_urls\": urls})\n\n    except Exception as e:\n        print(\"\u274c Imagen Edit Error:\", e)\n        return jsonify({\"error\": str(e)}), 50\n</code></pre>"},{"location":"reference/app/#img_gen_ai.app.logout","title":"logout","text":"<pre><code>logout()\n</code></pre> <p>Log out the current admin session.</p> Source code in <code>img_gen_ai/app.py</code> <pre><code>@app.route(\"/logout\")\ndef logout() -&gt; Response:\n    \"\"\"Log out the current admin session.\"\"\"\n    session.pop(\"is_admin\", None)\n    print(\"\ud83d\udc4b Superadmin logged out.\")\n    return redirect(url_for(\"login\"))\n</code></pre>"}]}